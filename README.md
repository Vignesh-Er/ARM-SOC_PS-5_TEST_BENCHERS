# ğŸš€ ARM-SOC_PS-5_TEST_BENCHERS  
## ARM_KRIA_KV260_HARDWARE_ACCELERATOR_FOR_MACHINE_LEARNING  

---

## ğŸ“Œ Project Overview

This repository contains a complete implementation of a **hardware-accelerated Convolutional Neural Network (CNN)** on the **AMD Xilinx Kria KV260 (K26 SOM)** platform.

The system demonstrates ARMâ€“FPGA hardware/software co-design for real-time object detection and achieves measurable performance improvement over CPU-only execution.

---

## ğŸ¯ Key Highlights

- âœ… Custom CNN accelerator using **Vitis HLS**
- âœ… AXI DMA-based high-speed PSâ€“PL communication
- âœ… Quantization-aware training (ap_fixed<16,6>)
- âœ… Real-time person detection demo
- âœ… >2Ã— speedup over CPU-only implementation
- âœ… Fully deployed on physical hardware (not simulation)

---

# ğŸ§  Problem Statement Reference

**Problem Statement 5**  
Real-Time Object Detection Using Hardware-Accelerated CNN  
(Bharat AI-SoC Student Challenge)

Objective:  
Design and implement a hardware-accelerated CNN inference system on a Zynq SoC and demonstrate measurable performance improvement over CPU-only execution.

---

# ğŸ— System Architecture

## Hardware Platform

- Board: Kria KV260 Vision AI Starter Kit  
- SoC: Zynq UltraScale+ MPSoC  
- PS: Quad-core ARM Cortex-A53  
- PL: FPGA Fabric  
- Interface: AXI4-Stream + AXI DMA  
- Runtime: PYNQ Linux  

---

## ğŸ”· Processing Partition

| Component        | Location | Function |
|------------------|----------|----------|
| Preprocessing    | PS       | Resize, Normalize |
| Convolution      | PL       | Accelerated CNN |
| Activation       | PL       | ReLU |
| Pooling          | PL       | Downsampling |
| Postprocessing   | PS       | NMS + Bounding Boxes |

---

## ğŸ”· Data Flow

```
Image / Camera
      â†“
Preprocessing (ARM - PS)
      â†“
AXI DMA (MM2S)
      â†“
CNN Accelerator (FPGA - PL)
      â†“
AXI DMA (S2MM)
      â†“
Postprocessing (ARM - PS)
      â†“
Detection Output
```

---

# âš™ï¸ Development Workflow

## 1ï¸âƒ£ Platform Setup

- Flashed PYNQ image to SD card
- Booted KV260
- Connected via Ethernet
- Accessed Jupyter Notebook

---

## 2ï¸âƒ£ Vitis HLS Accelerator

Implemented:

- 2D Convolution Engine  
- ReLU Activation  
- Max Pooling  
- AXI4-Stream Interface  
- AXI4-Lite Control Registers  

### Key Optimizations

```cpp
#pragma HLS PIPELINE II=1
#pragma HLS DATAFLOW
#pragma HLS ARRAY_PARTITION
```

Achieved:
- Initiation Interval (II) = 1  
- Efficient BRAM usage  
- High-throughput streaming architecture  

---

## 3ï¸âƒ£ Vivado Block Design

Integrated:

- Zynq MPSoC  
- AXI DMA (MM2S & S2MM)  
- Custom CNN HLS IP  
- AXI Interconnect  
- Clocking & Reset Modules  

Generated:

- design_1_wrapper.bit  
- design_1_wrapper.hwh  
- .xsa file  

---

## 4ï¸âƒ£ PYNQ Runtime Execution

Example Python Execution:

```python
overlay = Overlay("design_1_wrapper.bit")
dma.sendchannel.transfer(inp_buffer)
dma.recvchannel.transfer(out_buffer)
cnn_ip.write(0x00, 0x01)
dma.sendchannel.wait()
dma.recvchannel.wait()
```

---

# ğŸ§  Model Training & Quantization

### Challenges Faced

- Colab RAM crashes  
- Weight export issues  
- FP32 vs fixed-point mismatch  

### Solutions Implemented

- Disabled RAM caching  
- Monolithic training script  
- Fake quantization for ap_fixed<16,6>  

Final Model:

- Single-class (Person) detector  
- Quantization-aware trained  
- FPGA-compatible weights (.npy)  

---

# ğŸ“Š Performance Comparison

| Implementation | Latency |
|---------------|----------|
| CPU-only (PS) | ~630 ms |
| PS + PL       | ~215 ms |

### ğŸš€ Speedup Achieved

```
630 / 215 â‰ˆ 2.9Ã—
```

âœ” Exceeds required 2Ã— performance improvement.

---

# ğŸ›  Major Issues & Fixes

| Issue | Cause | Fix |
|-------|--------|------|
| DMA Hang | Missing TLAST | Added TLAST logic |
| No Detection | Weight mismatch | Retrained model |
| II > 1 | Memory dependency | Partitioned arrays |
| Timing violation | Over-unrolling | Balanced DSP usage |
| DDR stale data | Cache issue | Cache flush/invalidate |

---

# ğŸ“ˆ Resource Optimization

- Line-buffer architecture (3-row buffer)  
- ~70% BRAM reduction  
- Controlled DSP utilization  
- Stable AXI streaming  
- Deterministic execution  

---

# ğŸ† Achievements

- âœ” Custom CNN accelerator  
- âœ” Fully functional PSâ€“PL system  
- âœ” Stable AXI DMA communication  
- âœ” Real hardware deployment  
- âœ” >2Ã— measurable speedup  
- âœ” Accurate person detection  

---

# ğŸ“‚ Repository Structure

```
ARM-SOC_PS-5_TEST_BENCHERS/
â”‚
â”œâ”€â”€ hls/
â”‚   â”œâ”€â”€ cnn_accelerator.cpp
â”‚   â””â”€â”€ tb_cnn.cpp
â”‚
â”œâ”€â”€ vivado/
â”‚   â”œâ”€â”€ design_1_wrapper.bit
â”‚   â”œâ”€â”€ design_1_wrapper.hwh
â”‚
â”œâ”€â”€ pynq/
â”‚   â””â”€â”€ inference.py
â”‚
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ train.py
â”‚   â””â”€â”€ export_weights.py
â”‚
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ Final_Report.pdf
â”‚
â””â”€â”€ README.md
```

---

# ğŸ“ Learning Outcomes

- Vitis HLS optimization techniques  
- AXI protocol debugging  
- DMA system integration  
- Hardware-software co-design  
- Quantization-aware deployment  
- Real FPGA debugging  

---

# ğŸ”® Future Improvements

- Move NMS to FPGA  
- INT8 full pipeline  
- Multi-class expansion  
- Parallel convolution engines  
- Compare with Vitis AI DPU  

---

# ğŸ Conclusion

This project demonstrates a complete hardware-accelerated CNN inference system on the Kria KV260 platform using:

- Custom Vitis HLS IP  
- AXI DMA streaming  
- PSâ€“PL co-design  
- Quantization-aware training  
- Measurable real-world performance improvement  

This is a full-stack FPGA deployment project â€” not simulation-only.

---

## ğŸ“œ License

MIT License

---

## ğŸ‘¨â€ğŸ’» Author

Developed as part of Bharat AI-SoC Student Challenge â€“ Problem Statement 5.
